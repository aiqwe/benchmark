# human_eval
- Codex 모델의 벤치마크로 사용
- 사람이 수기로 작성한 164개의 질문셋
- Docstring이 주어졌을 때, 함수를 생성할 수 있는지 평가하며, 평가는 Unit-Test를 통해 자동화됨
- 언어 이해, 간단한 수학, 알고리즘, 소프트웨어 인터뷰 등의 문제들로 구성됨
---
+ **source**: huggingface
+ **hf_path**: openai/openai_humaneval
+ **url**: [https://huggingface.co/datasets/openai/openai_humaneval](https://huggingface.co/datasets/openai/openai_humaneval)  
+ **paper**: [https://arxiv.org/pdf/2107.03374](https://arxiv.org/pdf/2107.03374)  
